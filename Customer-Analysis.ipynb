{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "ab44b23f-0926-4c0d-930c-c536e4be18ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs\n",
    "ls /Volumes/sample_catalog/default/db_catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b7adc6c-f2ed-4da8-930c-4e50fdcdec03",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769003024642}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# /Volumes/sample_catalog/default/db_catalog \n",
    "\n",
    "df = spark.read.csv(\"/Volumes/sample_catalog/default/db_catalog/customer.csv\", header=True, inferSchema=True)\n",
    "#df.show()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0918a2e9-e57e-4bbe-b851-f49ef463f538",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "f1bbeb7d-a57b-463a-848c-ba6daa13a5d0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "# Define your own schema instead of inferSchema\n",
    "schema = StructType([\n",
    "    StructField(\"customer_id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"customer_type\", StringType(), True),\n",
    "    StructField(\"registration_date\", DateType(), True),\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"total_purchases\", IntegerType(), True),\n",
    "    StructField(\"ingestion_timestamp\", TimestampType(), True)\n",
    "])\n",
    "\n",
    "df1 = spark.read.csv(\"/Volumes/sample_catalog/default/db_catalog/customer.csv\", header=True, schema=schema)\n",
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4ef888fa-97dc-4399-a032-c1355fd618de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, column, when\n",
    "df1 = df.filter(df[\"customer_type\"] == \"VIP\")\n",
    "df2 = df.filter(column(\"customer_type\") == \"Regular\")\n",
    "df3 = df.filter(column(\"customer_type\") == \"Premimum\")\n",
    "df4 = df.filter(df.customer_type == \"VIP\")\n",
    "df5 = df.filter((df.customer_type == 'VIP') & (df.country == 'India'))\n",
    "\n",
    "df6 = df.where((df.customer_type == 'VIP') & (df.country == 'India'))\n",
    "df7 = df.where((df.customer_type == 'VIP') | (df.country == 'USA'))\n",
    "display(df7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "be2c7be4-ac73-42f9-af7c-53414fdc45c0",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769513560074}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.withColumn(\"Salary\", col(\"age\") * 1000)\n",
    "df1.printSchema()\n",
    "display(df1)\n",
    "\n",
    "df2 = df.withColumn(\"Seniority\", when(df.age>30, 'Senior').otherwise('Junior'))\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "48456eb8-dafb-4811-9d75-58fb2394317c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# to rename the column\n",
    "df3 = df2.withColumnRenamed(\"Seniority\", \"Is_Senior\")\n",
    "#display(df3)\n",
    "\n",
    "# to drop or delete the column\n",
    "df4 = df3.drop(\"Is_Senior\")\n",
    "#df4.printSchema()\n",
    "\n",
    "# to drop multiple colums\n",
    "df5 = df3.drop(\"Is_Senior\", \"Salary\", \"age\")\n",
    "df5.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "b06fedee-e0c0-4ffd-b697-1b0a0500949e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769514492728}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.select(\"age\", \"gender\", \"customer_type\")\n",
    "df2 =df.select(\"age\", \"gender\", \"customer_type\",col(\"age\")*1000)\n",
    "df3 =df.select(\"age\", \"gender\", \"customer_type\",(col(\"age\")*1000).alias(\"Salary\"))\n",
    "display(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "a5d08060-86c5-461b-ac5f-41be54e14034",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = spark.read.json(\"/Volumes/sample_catalog/default/db_catalog/SampleNested.json\")\n",
    "df2 = df1.select(\"address.city\", \"address.state\", \"age\", \"name\", \"email\")\n",
    "display(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "aa0cbcf5-921c-4442-9536-aff595785faa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df1 = df.filter(\"customer_type == 'VIP'\")\n",
    "df2 = df.filter(\"customer_type == 'Regular'\")\n",
    "\n",
    "df3 = df1.union(df2)\n",
    "df4 = df1.union(df2).union(df)\n",
    "df5 = df4.distinct()\n",
    "df6 = df4.select(\"customer_type\", \"country\").distinct()\n",
    "\n",
    "#display(df1)\n",
    "#display(df2)\n",
    "#display(df3)\n",
    "#display(df4)\n",
    "#display(df5)\n",
    "display(df6)\n",
    "\n",
    "\n",
    "#df1 = df.filter(\"customer_type == 'VIP'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f87c0ea5-2774-4213-ad6a-a4004c876aa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(df.count())   # count before the drop of null values\n",
    "df1 = df.na.drop()  # this function will eliminate all rows with null values\n",
    "print(df1.count())  # count after the drop of null values\n",
    "df1 = df.dropna()   # this function will eliminate all rows with null values\n",
    "\n",
    "df2 = df.filter(col(\"email\").isNull())\n",
    "#display(df2)\n",
    "\n",
    "df3 = df.na.fill(\"Unknown\")\n",
    "df4 =df.na.fill({\"email\": \"Unknown\", \"age\": 0})\n",
    "\n",
    "display(df4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1e475a53-60af-438f-85f3-9f5f583c9a3b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df1 = df.orderBy(\"age\")\n",
    "df2 = df.orderBy(\"age\", \"gender\")\n",
    "df3 = df.orderBy(desc(\"age\"))\n",
    "df4 = df.orderBy(desc(\"age\"), \"gender\")\n",
    "df5 = df.sort(desc(\"age\"))\n",
    "df6 = df.orderBy(col(\"email\").asc_nulls_first())\n",
    "df7 = df.orderBy(col(\"email\").asc_nulls_last())\n",
    "\n",
    "\n",
    "display(df7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12cee0a6-6eb0-4d66-be0d-e6e2dc53bc1e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769597126102}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, avg, max, min\n",
    "\n",
    "df1 = df.groupBy(\"gender\").count()\n",
    "df2 = df.groupBy(\"gender\", \"customer_type\").count()\n",
    "df3 = df.groupBy(\"gender\").sum(\"age\")\n",
    "df4 = df.groupBy(\"gender\").max(\"age\")\n",
    "df5 = df.groupBy(\"gender\").min(\"age\")\n",
    "df6 = df.groupBy(\"gender\").avg(\"age\")\n",
    "df7 = df.groupBy(\"gender\").agg(sum(\"age\"), max(\"age\"), min(\"age\"))\n",
    "df8 = df.groupBy(\"gender\").agg(sum(\"age\").alias(\"Sum\"), max(\"age\").alias(\"Highest\"), min(\"age\").alias(\"Lowest\"), avg(\"age\").alias(\"Average\"))\n",
    "\n",
    "display(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0cd6938a-b1d8-46d8-8cff-dbb4a839c84e",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769598750171}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import upper, lower, rtrim, ltrim, trim, regexp_replace, split, contains, length, concat_ws\n",
    "\n",
    "df1 = df.select(upper(\"country\"))\n",
    "df2 = df.select(lower(\"country\"))\n",
    "df3 = df.select(ltrim(\"country\").alias(\"New_Country\"), rtrim(\"country\"), trim(\"country\"))\n",
    "df4 = df.select(regexp_replace(col(\"country\"), \"Unknown\", \"Not Sure\"))\n",
    "df5 = df.select(\"email\", split(\"email\", \"@\"))\n",
    "df6 = df.select((\"email\"), col(\"email\").contains(\"customer\"))\n",
    "df7 = df.select(\"email\", length(\"email\"))\n",
    "df8 = df.select(concat_ws(\"@@\", \"age\", \"country\"))\n",
    "\n",
    "display(df8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb27c44c-5cc5-4c86-aca0-36e277c06c11",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769600180124}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df1 = df.select(\"registration_date\", year(\"registration_date\"), month(\"registration_date\"), dayofmonth(\"registration_date\"))\n",
    "#display(df1)\n",
    "\n",
    "df2 = df.select(\"registration_date\", dayofweek(\"registration_date\"), weekofyear(\"registration_date\"), dayofyear(\"registration_date\"), quarter(\"registration_date\"))\n",
    "#display(df2)\n",
    "\n",
    "df3 = df.select(\"registration_date\", date_add(\"registration_date\", 10), date_sub(\"registration_date\", 10))\n",
    "#display(df3)\n",
    "\n",
    "df4 = df.select(current_date()).limit(1)\n",
    "display(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43f31e6a-ce3f-43b1-b2a9-bac4e1f7fd51",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1769600818256}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "df1 = df.select(\"ingestion_timestamp\", year(\"ingestion_timestamp\"), month(\"ingestion_timestamp\"), dayofmonth(\"ingestion_timestamp\"), hour(\"ingestion_timestamp\"), minute(\"ingestion_timestamp\"), second(\"ingestion_timestamp\"))\n",
    "#display(df1)\n",
    "\n",
    "df2 = df.select(current_timestamp()).limit(1)\n",
    "#display(df2)\n",
    "\n",
    "df3 = df.select(\"ingestion_timestamp\", date_diff(current_timestamp(), \"ingestion_timestamp\"))\n",
    "display(df3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bf44c8d-8423-47af-b9ea-89de2726295d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6543212503880357,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Customer-Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
